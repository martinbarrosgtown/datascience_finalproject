---
title: "Remittances Data - Exploratory Data Analysis Consolidated"
author: "Cova, Langbehn, Villa & Barros" 
format: 
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    embed-resources: true
    theme: cosmo
editor: visual
---

# Setup and Data Loading

## Load Required Packages

```{r message=FALSE, warning=FALSE}
library(tidymodels)   
library(tidyverse)   
library(janitor)   
library(naniar)       
library(assertr)      
library(corrplot)
library(gridExtra)

## Turn off scientific notation for readable numbers
options(scipen = 999)
```

## Load the Data

Filler out Missing Values in our key predicted outcome as this will cause our predicted models to fail, it provides no addtiaional data to our model. However for missingness in our predictors, imputation will help ensure non-systemic missingness adversely effects the sample size of our model.

```{r message=FALSE, warning=FALSE}
## Read in the CSV file
remittances <- read_csv("remittances.csv") |>
  filter(!is.na(remittances_gdp)
```

## Create Training and Testing Splits

```{r}
## Set seed for reproducibility
set.seed(20251211)

## Split data: 80% training, 20% testing
remit_split <- initial_split(data = remittances, prop = 0.8)
remit_train <- training(x = remit_split) 
remit_test <- testing(x = remit_split)
```

------------------------------------------------------------------------

## STEP 1: Data Overview

## Get a Quick Look at the Data Structure

```{r}
## View the first few rows and column types
glimpse(remit_train)
```

The training data has **3,918 rows** and **19 columns**. We can see:

-   Character columns: country_name, country_code
-   Numeric columns: year, remittances, gdp, unemployment, etc.

## Calculate Summary Statistics

```{r}
## Get min, max, mean, median for all variables
summary(remit_train)
```

Key observations:

-   Years range from 1994 to 2024 (30 years of data)
-   Remittances range from \$11,470 to \$137.7 billion per county.

## Check Internal Structure

```{r}
## Detailed structure of the data
str(remit_train)
```

All numeric variables are stored as `num` or `dbl` (double precision), and text variables are stored as `chr` (character).

------------------------------------------------------------------------

## STEP 2: Column Names and Types

## View Original Column Names

```{r}
## Check current column names
names(remit_train)
```

Some column names have spaces and capital letters.

## Clean Column Names to Snake Case

```{r}
## Convert to lowercase with underscores
remit_train <- remit_train |>
  clean_names()

## Verify the cleaned names
names(remit_train)
```

Now all column names are lowercase with underscores.

------------------------------------------------------------------------

## STEP 3: Missing Data Analysis

## Count Missing Values by Column

```{r}
## Count NA values in each column
colSums(is.na(remit_train))
```

Several variables have missing data. Let's calculate the percentage!

## Calculate Percentage of Missing Data

```{r}
## Calculate percent missing for each variable
remit_train |>
  summarise(across(everything(), ~sum(is.na(.)) / n() * 100))
```

**Major findings:**

-   **poverty**: 64 % missing
-   **stock**:49.82.8% missing
-   **remittances**: % missing
-   **remittances_gdp**: 16.3% missing

------------------------------------------------------------------------

## STEP 4: Outlier Detection and Distribution Analysis

## Examine Remittances (Our Target Variable)

### Summary Statistics for Remittances

```{r}
## Get min, max, mean, median, quartiles
summary(remit_train$remittances)
```

The mean (\$2.55 billion) is much larger than the median (\$529 million). The data is **right-skewed**.

### Check overall data distribution

```{r fig.width=10, fig.height=5}
## Create a point plot (from class notes Section 5.6.1)
remit_train |>
  select(remittances, remittances_gdp, gdp, stock, unemployment,deportations) |>
  pivot_longer(everything()) |>
  ggplot(aes(value)) +
  geom_histogram(bins = 30) +
  facet_wrap(~name, scales = "free") +
  theme_minimal()

#CAVEAT: I could not 'clean' the x axis (log would be the way to solve it but 
#we want to show how skewed the distribution is)

```

### Point Plot to See Distribution

```{r fig.width=10, fig.height=5}
## Create a point plot (from class notes Section 5.6.1)
remit_train |>
  ggplot(aes(remittances, 1)) +
  geom_point(alpha = 0.2) +
  scale_y_continuous(breaks = 0) +
  labs(y = NULL, title = "Distribution of Remittances") +
  theme_bw() +
  theme(panel.border = element_blank())
```

Most points cluster on the left (lower values) with a few extreme points on the right (confirms right-skewness).

### Histogram to See Frequency Distribution

```{r fig.width=10, fig.height=6}
## Create histogram with 30 bins
remit_train |>
  ggplot(aes(x = remittances)) +
  geom_histogram(bins = 30, fill = "steelblue") +
  theme_minimal() +
  labs(title = "Distribution of Remittances",
       x = "Remittances (USD)",
       y = "Count")
```

The histogram is heavily concentrated on the left with a long tail to the right. This is classic right-skewed data.

### Boxplot to Identify Outliers

```{r fig.width=10, fig.height=6}
## Create boxplot to see outliers
remit_train |>
  ggplot(aes(y = remittances)) +
  geom_boxplot(fill = "steelblue") +
  theme_minimal() +
  labs(title = "Boxplot of Remittances",
       y = "Remittances (USD)")
```

Many points appear above the upper whisker (outliers). These are likely large countries like Mexico that receive billions in remittances.

## Examine GDP

### Summary Statistics for GDP

```{r}
## Get summary statistics
summary(remit_train$gdp)
```

GDP also shows huge range - from \$21 million to \$18.7 trillion.

### Point Plot for GDP Distribution

```{r fig.width=10, fig.height=5}
## Create point plot for GDP
remit_train |>
  ggplot(aes(gdp, 1)) +
  geom_point(alpha = 0.2) +
  scale_y_continuous(breaks = 0) +
  labs(y = NULL, title = "Distribution of GDP") +
  theme_bw() +
  theme(panel.border = element_blank())
```

GDP shows the same right-skewed pattern as remittances. Large economies have much higher GDP than small economies.

## Examine Unemployment

### Summary Statistics for Unemployment

```{r}
## Get summary statistics
summary(remit_train$unemployment)
```

Unemployment ranges from 0.11% to 34.01%.

### Point Plot for Unemployment Distribution

```{r fig.width=10, fig.height=5}
## Create point plot for unemployment
remit_train |>
  ggplot(aes(unemployment, 1)) +
  geom_point(alpha = 0.2) +
  scale_y_continuous(breaks = 0) +
  labs(y = NULL, title = "Distribution of Unemployment") +
  theme_bw() +
  theme(panel.border = element_blank())
```

Unemployment appears more evenly distributed than remittances or GDP.

## Examine Inflation

### Summary Statistics for Inflation

```{r}
## Get summary statistics
summary(remit_train$inflation)
```

The maximum inflation is 6,041%! (outlier) Most inflation values are between 1.7% and 9%,

### Point Plot for Inflation Distribution

```{r fig.width=10, fig.height=5}
## Create point plot for inflation
remit_train |>
  ggplot(aes(inflation, 1)) +
  geom_point(alpha = 0.2) +
  scale_y_continuous(breaks = 0) +
  labs(y = NULL, title = "Distribution of Inflation") +
  theme_bw() +
  theme(panel.border = element_blank())
```

## Data Quality Unit Tests

### Test 1: Are All Remittances Positive?

```{r}
## Test that remittances > 0 when not missing
remit_train |>
  filter(!is.na(remittances)) |>
  verify(remittances > 0) |>
  summarise(mean_remittances = mean(remittances, na.rm = TRUE))
```

All remittances are positive. The mean is \$2.55 billion.

### Test 2: Are All Years in Valid Range?

```{r}
## Test that years are between 1994 and 2024
remit_train |>
  verify(year >= 1994 & year <= 2024) |>
  summarise(mean_year = mean(year))
```

All years are within the expected range.

### Test 3: Are All Unemployment Values Valid?

```{r}
## Test that unemployment is between 0 and 100
remit_train |>
  filter(!is.na(unemployment)) |>
  verify(unemployment >= 0 & unemployment <= 100) |>
  summarise(mean_unemployment = mean(unemployment, na.rm = TRUE))
```

All unemployment values are valid percentages (0-100%).

------------------------------------------------------------------------

# STEP 5: Log Transformations for Skewed Variables

Since remittances and GDP are highly right-skewed, we need to create and examine log.

## Create Log-Transformed Variables

```{r}
## Create log-transformed versions of skewed variables
remit_train <- remit_train |>
  mutate(
    log_remittances = log(remittances + 1),
    log_gdp = log(gdp + 1)
  )
```

We add 1 before taking the log to handle any zero values (log(0) is undefined).

## Examine Log-Transformed Remittances

### Summary Statistics for Log Remittances

```{r}
## Get summary statistics for log remittances
summary(remit_train$log_remittances)
```

### Histogram of Log Remittances

```{r fig.width=10, fig.height=6}
## Create histogram for log-transformed remittances
remit_train |>
  filter(!is.na(log_remittances)) |>
  ggplot(aes(x = log_remittances)) +
  geom_histogram(bins = 30, fill = "darkgreen", color = "white") +
  theme_minimal() +
  labs(title = "Distribution of Log-Transformed Remittances",
       subtitle = "Much more normal distribution after log transformation",
       x = "Log(Remittances + 1)",
       y = "Count")
```

The log-transformed remittances show a much more normal distribution compared to the original right-skewed data.

### Boxplot of Log Remittances

```{r fig.width=10, fig.height=6}
## Create boxplot for log remittances
remit_train |>
  filter(!is.na(log_remittances)) |>
  ggplot(aes(y = log_remittances)) +
  geom_boxplot(fill = "darkgreen") +
  theme_minimal() +
  labs(title = "Boxplot of Log-Transformed Remittances",
       y = "Log(Remittances + 1)")
```

Fewer outliers visible after log transformation.

## Examine Log-Transformed GDP

### Summary Statistics for Log GDP

```{r}
## Get summary statistics for log GDP
summary(remit_train$log_gdp)
```

### Histogram of Log GDP

```{r fig.width=10, fig.height=6}
## Create histogram for log-transformed GDP
remit_train |>
  filter(!is.na(log_gdp)) |>
  ggplot(aes(x = log_gdp)) +
  geom_histogram(bins = 30, fill = "darkblue", color = "white") +
  theme_minimal() +
  labs(title = "Distribution of Log-Transformed GDP",
       subtitle = "More normal distribution after log transformation",
       x = "Log(GDP + 1)",
       y = "Count")
```

Log GDP also shows a more normal distribution.

## Compare Original vs Log-Transformed

### Side-by-Side: Original vs Log Remittances

```{r fig.width=12, fig.height=5}
## Create comparison plots
p1 <- remit_train |>
  filter(!is.na(remittances)) |>
  ggplot(aes(x = remittances)) +
  geom_histogram(bins = 30, fill = "steelblue") +
  theme_minimal() +
  labs(title = "Original Remittances (Right-Skewed)",
       x = "Remittances (USD)")

p2 <- remit_train |>
  filter(!is.na(log_remittances)) |>
  ggplot(aes(x = log_remittances)) +
  geom_histogram(bins = 30, fill = "darkgreen") +
  theme_minimal() +
  labs(title = "Log-Transformed Remittances (More Normal)",
       x = "Log(Remittances + 1)")

grid.arrange(p1, p2, ncol = 2)
```

The log transformation successfully converts the right-skewed distribution into a more normal distribution, which is better for modeling.

### Side-by-Side: Original vs Log GDP

```{r fig.width=12, fig.height=5}
## Create comparison plots for GDP
p3 <- remit_train |>
  filter(!is.na(gdp)) |>
  ggplot(aes(x = gdp)) +
  geom_histogram(bins = 30, fill = "steelblue") +
  theme_minimal() +
  labs(title = "Original GDP (Right-Skewed)",
       x = "GDP (USD)")

p4 <- remit_train |>
  filter(!is.na(log_gdp)) |>
  ggplot(aes(x = log_gdp)) +
  geom_histogram(bins = 30, fill = "darkblue") +
  theme_minimal() +
  labs(title = "Log-Transformed GDP (More Normal)",
       x = "Log(GDP + 1)")

grid.arrange(p3, p4, ncol = 2)
```

## Relationship: Log GDP vs Log Remittances

```{r fig.width=10, fig.height=6}
## Scatter plot with log-transformed variables
remit_train |>
  filter(!is.na(log_gdp), !is.na(log_remittances)) |>
  ggplot(aes(x = log_gdp, y = log_remittances)) +
  geom_point(alpha = 0.3, color = "steelblue") +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  theme_minimal() +
  labs(title = "Log GDP vs Log Remittances",
       subtitle = "Clearer linear relationship after log transformation",
       x = "Log(GDP + 1)",
       y = "Log(Remittances + 1)")
```

The relationship between log GDP and log remittances is **more linear** than the original variables, which will improve model performance.

## Assessing deportations and remittances

```{r fig.width=10, fig.height=6}
ggplot(remit_train, aes(x = deportations + 1, y = remittances + 1)) +
  geom_point(alpha = 0.3, color = "steelblue") +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  scale_x_log10() +
  scale_y_log10() +
  labs(
    title = "Log–Log Relationship Between Deportations and Remittances",
    x = "Log(Deportations + 1)",
    y = "Log(Remittances + 1)"
  ) +
  theme_minimal()
```

-   On a log–log scale, deportations and remittances show a positive but noisy association, suggesting remittances tend to rise with deportations.

------------------------------------------------------------------------

# STEP 6: Categorical Variables Analysis

## Count Unique Countries

```{r}
## Count distinct country names
n_distinct(remit_train$country_name)
```

We have 158 different countries in the dataset.

## View Frequency Table (First 20 Countries)

```{r}
## Show how many observations per country
head(table(remit_train$country_name), 20)
```

Most countries have between 20-30 observations, representing roughly 20-30 years of data.

## Create Bar Chart of Top 20 Countries

```{r fig.width=10, fig.height=8}
## Count observations per country and plot top 20
remit_train |>
  count(country_name, sort = TRUE) |>
  slice_head(n = 20) |>
  ggplot(aes(x = reorder(country_name, n), y = n)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Top 20 Countries by Number of Observations",
       x = "Country",
       y = "Count")
```

Countries are fairly evenly represented. Bahrain has the most observations (30), while several countries have around 20-29 observations.

## Create Bar Chart of Top 15 by total remittances (2024) & Top 15 by remittances/GDP (2024)

```{r}

remit_train %>%
  filter(year == 2024) %>%
  slice_max(remittances, n = 15) %>%
  ggplot(aes(
    x = fct_reorder(country_name, remittances),
    y = remittances / 1e9
  )) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Top 15 Remittance Receivers (2024)",
    x = "Country",
    y = "Remittances (Billions USD)"
  ) +
  theme_minimal()

# Top 15 by remittances/GDP (2024)
remit_train %>%
  filter(year == 2024) %>%
  slice_max(remittances_gdp, n = 15) %>%   # preferred over top_n()
  mutate(`Country Name` = fct_reorder(country_name, remittances_gdp)) %>%
  ggplot(aes(x = `Country Name`, y = remittances_gdp)) +
  geom_col(fill = "coral") +
  coord_flip() +
  labs(
    title = "Top 15 Countries: Remittances as % GDP (2024)",
    x = "Country",
    y = "Remittances (% GDP)"
  ) +
  theme_minimal()
```

## Top 10 countries - Remittances as a % of the GDP

```{r}
remit_train |>
  group_by(country_name) |>
  summarize(mean_ratio = mean(remittances_gdp, na.rm = TRUE)) |>
  arrange(desc(mean_ratio)) |>
  slice_head(n = 10)

top10 <- remit_train |>
  group_by(country_name) |>
  summarize(mean_ratio = mean(remittances_gdp, na.rm = TRUE)) |>
  arrange(desc(mean_ratio)) |>
  slice_head(n = 10)

ggplot(top10, aes(x = reorder(country_name, mean_ratio), y = mean_ratio)) +
  geom_col(fill = "coral") +
  coord_flip() +
  labs(
    title = "Top 10 Countries by Average Remittances % of GDP",
    x = "Country",
    y = "Average Remittances/GDP"
  ) +
  theme_minimal()

```

## Remittances per country (Original Scale)

```{r fig.width=10, fig.height=6}
remit_train |>
  filter(country_name %in% c(
    "Nicaragua", "El Salvador", "Honduras", "Guatemala", "Haiti", "India"
  )) |>
  ggplot(aes(x = year, y = remittances_gdp, color = country_name)) +
  geom_line(linewidth = 1) +
  scale_y_log10() +
  labs(
    title = "Remittance Trends Over Time",
    subtitle = "Selected Countries (log scale)",
    x = "Year",
    y = "Remittances (% of GDP, log scale)",
    color = "Country"
  ) +
  theme_minimal()

```

## Start assessing countries of interest

```{r fig.width=10, fig.height=6}
#Start assessing countries of interes
countries_of_interest <- c( "Nicaragua", "El Salvador", "Honduras", "Guatemala", 
                            "Haiti", "India")

filtered <- remit_train |>
  filter(country_name %in% countries_of_interest)

ggplot(filtered, aes(log(stock), log(remittances), color = country_name)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    x = "log(stock)",
    y = "log(remittances)",
    title = "Stock–Remittance Relationship for Selected Countries",
    color = "Country"
  ) +
  theme_minimal()

#Comment: comparing the stock–Remittance Relationship for Selected Countries
```

------------------------------------------------------------------------

# STEP 6: Relationships Between Variables

## GDP vs Remittances (Original Scale)

```{r fig.width=10, fig.height=6}
## Scatter plot with trend line
remit_train |>
  ggplot(aes(x = gdp, y = remittances)) +
  geom_point(alpha = 0.3, color = "steelblue") +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  theme_minimal() +
  labs(title = "Relationship Between GDP and Remittances (Original Scale)",
       x = "GDP (USD)",
       y = "Remittances (USD)")
```

There is a clear positive relationship. Countries with larger economies (higher GDP) tend to receive more remittances in absolute dollar amounts. The red line shows the linear trend.

## Log GDP vs Log Remittances (Better for Modeling)

```{r fig.width=10, fig.height=6}
## Scatter plot with log-transformed variables
remit_train |>
  filter(!is.na(log_gdp), !is.na(log_remittances)) |>
  ggplot(aes(x = log_gdp, y = log_remittances)) +
  geom_point(alpha = 0.3, color = "darkgreen") +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  theme_minimal() +
  labs(title = "Log GDP vs Log Remittances (Log Scale - Better Linear Fit)",
       subtitle = "This relationship is more appropriate for linear regression models",
       x = "Log(GDP + 1)",
       y = "Log(Remittances + 1)")
```

The log-transformed relationship is **more linear** and will produce better model predictions.

## GDP Per Capita vs Remittances as % of GDP

```{r fig.width=10, fig.height=6}
## Scatter plot with trend line
remit_train |>
  ggplot(aes(x = gdp_per, y = remittances_gdp)) +
  geom_point(alpha = 0.3, color = "steelblue") +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  theme_minimal() +
  labs(title = "GDP Per Capita vs Remittances as % of GDP",
       x = "GDP Per Capita (USD)",
       y = "Remittances as % of GDP")
```

Poorer countries (lower GDP per capita) depend more heavily on remittances as a percentage of their economy. Richer countries receive remittances but they represent a smaller share of their total GDP.

## Unemployment vs Remittances

```{r fig.width=10, fig.height=6}
## Scatter plot with trend line
remit_train |>
  ggplot(aes(x = unemployment, y = remittances)) +
  geom_point(alpha = 0.3, color = "steelblue") +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  theme_minimal() +
  labs(title = "Unemployment vs Remittances",
       x = "Unemployment Rate (%)",
       y = "Remittances (USD)")
```

There is a **slight negative relationship** (it is weak). Unemployment doesn't appear to be a strong predictor of remittances.

## Correlation Matrix (Numbers)

```{r}
## Calculate correlations between all numeric variables
remit_train |>
  select(where(is.numeric)) |>
  cor(use = "complete.obs") |>
  round(2)
```

-   **gdp and remittances: 0.46** - Moderate positive (as GDP increases, remittances increase)
-   **log_gdp and log_remittances: Check the correlation matrix** - Likely stronger correlation
-   **stock and deportations: 0.73** - Strong positive (might cause multicollinearity issues)
-   **dist_pop and dist_cap: 1.00** - Perfect correlation! These measure essentially the same thing. **We must drop one.**
-   **internet and year: 0.69** - Strong positive (internet access increases over time)
-   **gdp_per and vulnerable_emp: -0.63** - Strong negative (richer countries have less vulnerable employment)

## Correlation Matrix (Heatmap)

```{r fig.width=12, fig.height=10}
## Create visual correlation matrix (Eva's example)
remit_train |>
  select(where(is.numeric)) |>
  cor(use = "complete.obs") |>
  corrplot(method = "color", 
           type = "upper",
           tl.col = "black",
           tl.srt = 45,
           title = "Correlation Matrix",
           mar = c(0,0,2,0))
```

-   **Blue squares** = positive correlation (variables increase together)
-   **Red squares** = negative correlation (one increases, other decreases)
-   **Darker colors** = stronger correlation

```{r}
## Create visual correlation matrix (Gaby's example)
library(reshape2)

#Create variable to represent numeric vars 
numeric_vars_log <- remit_train %>%
  select(remittances_gdp, remittances, stock, unemployment, gdp_per, 
         inflation, internet, dist_cap, terror) %>%
  mutate(
    remittances_gdp = log1p(remittances_gdp),
    remittances     = log1p(remittances),
    stock            = log1p(stock),        # migrant stock
    gdp_per          = log1p(gdp_per),
    internet         = log1p(internet),
    dist_cap         = log1p(dist_cap)
  ) %>%
  na.omit()

cor_matrix_log <- cor(numeric_vars_log, use = "complete.obs")
melted_cor_log <- melt(cor_matrix_log)

ggplot(melted_cor_log, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  geom_text(aes(label = round(value, 2)), size = 3) +
  scale_fill_gradient2(
    low = "blue", mid = "white", high = "red",
    midpoint = 0, limits = c(-1, 1)
  ) +
  labs(title = "Correlation Heatmap (Log-Transformed Variables)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

-   Remittances are most strongly positively correlated with the stock of migrants (0.49), suggesting migrant presence is a key driver, while other macro variables show only weak associations.
-   Remittances as % of GDP are negatively correlated with GDP per capita ( −0.48), indicating remittances matter more (relative to GDP) in poorer countries.

------------------------------------------------------------------------

# STEP 7: Time Trends Analysis

## Remittances Over Time

```{r fig.width=12, fig.height=6}
## Calculate average remittances per year and plot
remit_train |>
  group_by(year) |>
  summarise(avg_remittances = mean(remittances, na.rm = TRUE)) |>
  ggplot(aes(x = year, y = avg_remittances)) +
  geom_line(color = "steelblue", linewidth = 1) +
  geom_point(color = "steelblue") +
  theme_minimal() +
  labs(title = "Average Remittances Over Time (1994-2024)",
       x = "Year",
       y = "Average Remittances (USD)")
```

Remittances show a clear upward trend over 30 years. We can see:

-   Steady growth from 1994 to 2008.
-   A dip around 2008-2009 (global financial crisis).
-   Recovery and continued growth.
-   Another dip around 2020 (COVID-19 pandemic).
-   Strong rebound after 2020.

## Remittances as % of GDP Over Time

```{r fig.width=12, fig.height=6}
## Calculate average remittances as % of GDP per year and plot
remit_train |>
  group_by(year) |>
  summarise(avg_remittances_gdp = mean(remittances_gdp, na.rm = TRUE)) |>
  ggplot(aes(x = year, y = avg_remittances_gdp)) +
  geom_line(color = "steelblue", linewidth = 1) +
  geom_point(color = "steelblue") +
  theme_minimal() +
  labs(title = "Average Remittances as % of GDP Over Time",
       x = "Year",
       y = "Remittances as % of GDP")
```

Remittances as a percentage of GDP have stayed relatively **stable around 3-4%** over time. This means remittances are growing roughly in line with GDP growth, not becoming more or less important to economies over time.

------------------------------------------------------------------------

# STEP 8: Exploring lagged effects

It is likely that past changes to country of origin conditions is likely to be more illustrative of future remittances than current conditions. For example, while a downward shock in GDP may influence current migration, migrants may take time to settle into the US and thus begin remitting back home.

These lagged effect would seem to be the most plausible with GDP, unemployment, terror, deportations, and changes in migrant stock (inward migration)

```{r}
## Lagged (1 year)
remit_lag <- remit_train |>
  mutate(year = as.numeric(year)) |>
  arrange(country_name, year) |>
  group_by(country_name) |>
  mutate(
    gdp_lag = lag(gdp_per),
    unemp_lag = lag(unemployment), 
    terror_lag = lag(terror), 
    deportations_lag = lag(deportations), 
    stock_lag = lag(stock), 
  ) |>
  ungroup()
# Verifying that the lag worked. 
remit_lag |>
  select(country_name, year, gdp_per, gdp_lag) |>
  arrange(country_name, year) |>
  filter(!is.na(gdp_lag)) |>
  slice_head(n = 10)
```

## Lagged GDP per Capita

```{r message=FALSE, warning=FALSE}
## Lagged predictors relationship with remittances (as % of GDP)

## GDP per capita
# Lagged vs Unlagged
remit_lag |>
  pivot_longer(cols = c(gdp_per, gdp_lag),
               names_to = "type",
               values_to = "value") |>
  ggplot(aes(value, remittances_gdp, color = type)) +
  geom_point(alpha = 0.3) +
  geom_smooth(se = FALSE) +
  theme_minimal() +
  labs(title = "Lagged vs Current GDP per Capita",
       x = "GDP per capita",
       color = "Variable") ## Doesn't Necessarily Improve Model Fit. 
```

Overall there seem to be better ways to verify whether lagged variable would improve the interpretability of our models.

```{r message=FALSE, warning=FALSE}
## Comparing Lagged vs Current GDP per capita for key countries. 
remit_lag |>
  filter(country_name %in% c("Nicaragua", "El Salvador", "Honduras",
                             "Guatemala", "Haiti", "India")) |>
  pivot_longer(
    cols = c(gdp_per, gdp_lag),
    names_to = "gdp_type",
    values_to = "gdp_value"
  ) |>
  ggplot(aes(x = gdp_value, y = remittances_gdp,
             color = country_name, linetype = gdp_type)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() +
  labs(
    title = "Lagged vs Current GDP per Capita",
    x = "GDP per capita (current or lagged)",
    linetype = "GDP variable"
  )

```

Suggestion is that Lagged GDP demonstrates a slightly stronger relationship and thus may improve model fit. Thus it may seem that shocks or changes to prior GDP could help explain current remittances amounts.

## Lagged Unemployment

```{r message=FALSE, warning=FALSE}
## Comparing Lagged vs Current Unemployment for key countries. 
remit_lag |>
  filter(country_name %in% c("Nicaragua", "El Salvador", "Honduras",
                             "Guatemala", "Haiti", "India")) |>
  pivot_longer(
    cols = c(unemployment, unemp_lag),
    names_to = "unemp_type",
    values_to = "unemp_value"
  ) |>
  ggplot(aes(x = unemp_value, y = remittances_gdp,
             color = country_name, linetype = unemp_type)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() +
  labs(
    title = "Lagged vs Current Unemployment",
    x = "Unemployment (current or lagged)",
    linetype = "GDP variable"
  )

```

For most countries lagged unemployment does not seem to alter model fit substantially for any country other than Haiti.

It likely won't improve our model fit and thus shouldn't be included.

## Lagged Changes in Terror Level

```{r message=FALSE, warning=FALSE}
## Comparing Lagged vs Current Terror for key countries. 
remit_lag |>
  filter(country_name %in% c("Nicaragua", "El Salvador", "Honduras",
                             "Guatemala", "Haiti", "India")) |>
  pivot_longer(
    cols = c(terror, terror_lag),
    names_to = "terror_type",
    values_to = "terror_value"
  ) |>
  ggplot(aes(x = terror_value, y = remittances_gdp,
             color = country_name, linetype = terror_type)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() +
  labs(
    title = "Lagged vs Current Terror",
    x = "Terror (current or lagged)",
    linetype = "Terror variable"
  )

```

It seems terror varies less, and lagged terror levels may not be too explanatory

## Lagged Changes in Deportations

```{r message=FALSE, warning=FALSE}
## Comparing Lagged vs Current Deportations for key countries. 
remit_lag |>
  filter(country_name %in% c("Nicaragua", "El Salvador", "Honduras",
                             "Guatemala", "Haiti", "India")) |>
  pivot_longer(
    cols = c(deportations, deportations_lag),
    names_to = "deportations_type",
    values_to = "deportations_value"
  ) |>
  ggplot(aes(x = deportations_value, y = remittances_gdp,
             color = country_name, linetype = deportations_type)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() +
  labs(
    title = "Lagged vs Current Deportations",
    x = "Deportations (current or lagged)",
    linetype = "Deportations variable"
  )

```

Much stronger relationship for key countries in including the lagged effects of deportations in explaining future remittances.

```{r message=FALSE, warning=FALSE}
## Comparing Lagged vs Current Deportations for key countries. 
remit_lag |>
  filter(country_name %in% c("Nicaragua", "El Salvador", "Honduras",
                             "Guatemala", "Haiti", "India")) |>
  pivot_longer(
    cols = c(stock, stock_lag),
    names_to = "stock_type",
    values_to = "stock_value"
  ) |>
  ggplot(aes(x = stock_value, y = remittances_gdp,
             color = country_name, linetype = stock_type)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() +
  labs(
    title = "Lagged vs Current Changes in Migrant Stock ",
    x = "Migrant Stock (current or lagged)",
    linetype = "Migrant Stock variable"
  )
```

Less Strong change and thus probably doesn't warrant inclusion.

**Takeaways:**

-   Predictive power of lagged deportations and GDP improve model fit the best (shift the slopes of our relationships most).

-   For the other predictors, including changes to migrant stock, terror, and unemployment the relationships for our key variables barely changed indicating no changes in explanatory power.

-   **Next Steps:** using `step_mutate` in our recipe to add lags to our `gdp_per` and `deportations` would account for this.

------------------------------------------------------------------------

# STEP 9: Cross-validation set up

```{r}
## To improve the accuracy of our estimated error rates, we set up a 10-fold cross validation with 5 repetitions since we have a relatively small number of observations within the training data
remit_folds <- vfold_cv(data = remit_train, v = 10, repeats = 5)
```

```{r}
## Recipe (baseline model)
recipe_baseline <- 
  recipe(remittances_gdp ~ stock + gdp_per + unemployment + dist_cap + terror + deportations + internet + inflation,
  data = remit_train) |>
step_impute_median(all_numeric_predictors()) |>
step_impute_mode(all_nominal_predictors())|>
step_mutate(
  gdp_lag = lag(gdp_per), 
  unemp_lag = lag(unemployment)) |>
step_mutate(
    gdp_per = log(gdp_per + 1)) |>
step_normalize(all_numeric_predictors())

## Processing the full training data using parameter specification. 
bake(prep(recipe_baseline, training = remit_train), new_data = remit_train)
```

------------------------------------------------------------------------

## STEP 10: Model Comparison and Evaluation

In this section, we compare five different regression models to predict remittances as a percentage of GDP.

------------------------------------------------------------------------

## 10.1 OLS Baseline Model

```{r}
## Linear model
lm_baseline <- linear_reg() |>
  set_mode(mode = "regression") |>
  set_engine(engine = "lm")

## Create workflow
lm_workflow <- workflow() |>
  add_recipe(recipe_baseline) |>
  add_model(lm_baseline)

## Fit model
lm_results <- lm_workflow |>
  fit_resamples(resamples = remit_folds)

## Collect RMSE
collect_metrics(lm_results)
```

Establishes a baseline performance using ordinary least squares regression with no regularization. This gives us a benchmark to compare other models against.

------------------------------------------------------------------------

## 10.2 Prepare Enhanced Recipe for Regularized Models

```{r}
library(tidymodels)
library(glmnet)
library(dplyr)

#We clean remittances before folding due to missing values
train_data2 <- remit_train %>%
  filter(!is.na(remittances_gdp))   
remit_folds <- vfold_cv(train_data2, v = 10)

#At first, glmnet was throwing errors, so we need to create a recipe that forces
#your predictors into a form that ridge/lasso (glmnet) can handle, with no NA, no Inf / -Inf
#no constant columns, comparable scales across predictors.

recipe_glmnet <- recipe_baseline %>%
  step_mutate(across(all_numeric_predictors(),
                     ~ if_else(is.finite(.x), .x, NA_real_))) %>% 
  step_impute_median(all_numeric_predictors()) %>%               
  step_impute_mode(all_nominal_predictors()) %>%                 
  step_zv(all_predictors()) %>%                                  
  step_normalize(all_numeric_predictors())                       

ctrl <- control_grid(save_pred = TRUE, verbose = TRUE)
grid30 <- grid_regular(penalty(), levels = 30)

metrics1 <- metric_set(rmse)

#This control object makes errors visible and traceable
```

------------------------------------------------------------------------

## 10.3 RIDGE Regression

```{r}
#this defines ridge regression with a tuned penalty.
ridge_spec <- linear_reg(penalty = tune(), mixture = 0) %>%
  set_mode("regression") %>%
  set_engine("glmnet")

# build the workflow (recipe + model)
ridge_wf <- workflow() %>%
  add_recipe(recipe_glmnet) %>%
  add_model(ridge_spec)

#We tune the penalty using cross-validation
ridge_res <- tune_grid(
  ridge_wf,
  resamples = remit_folds,
  grid = grid30,
  metrics = metrics1,
  control = ctrl
)

best_ridge <- select_best(ridge_res, metric = "rmse")
final_ridge_wf <- finalize_workflow(ridge_wf, best_ridge)
ridge_fit <- fit(final_ridge_wf, data = train_data2)

# results
best_ridge
final_ridge_wf
ridge_fit 
```

### Comment:

-   penalty value with the lowest RMSE: best_ridge has a penalty \~ 0. The penalty disappears, with the model becomes almost identical to standard linear regression. The cross-validation procedure
-   shows that adding regularization does not improve predictive performance relative to an unpenalized linear model.
-   ridge_fit shows that ridge ≈ OLS Coefficients will be very similar to baseline linear model

### Conclusion:

The ridge regression regularization indicated increasing deviance as the penalty decreased, with cross-validation selecting a penalty effectively equal to zero. This suggests that the unpenalized linear model already provides an optimal fit for the data.

------------------------------------------------------------------------

## 10.4 LASSO Regression

```{r}
# we specify the LASSO model
lasso_spec <- linear_reg(penalty = tune(), mixture = 1) %>%
  set_mode("regression") %>%
  set_engine("glmnet")

# we build the workflow - preprocess to prevent leakage
lasso_wf <- workflow() %>%
  add_recipe(recipe_glmnet) %>%
  add_model(lasso_spec)

# Tune lambda penalty  using cross-validation
lasso_res <- tune_grid(
  lasso_wf,
  resamples = remit_folds,
  grid = grid30,
  metrics = metrics1,
  control = ctrl
)

# choose the best lambda (lowest RMSE)
best_lasso <- select_best(lasso_res, metric = "rmse")
# finalize the workflow
final_lasso_wf <- finalize_workflow(lasso_wf, best_lasso)
# fit the final LASSO model on all training data
lasso_fit <- fit(final_lasso_wf, data = train_data2)

best_lasso
final_lasso_wf
lasso_fit

tidy(lasso_fit) %>%
  filter(term != "(Intercept)") %>%
  filter(estimate != 0) %>%
  arrange(desc(abs(estimate)))
```

### Calculating the RMSE

```{r}
# RMSE comparison
bind_rows(
  collect_metrics(ridge_res) |>
    filter(.metric == "rmse") |>
    inner_join(best_ridge, by = "penalty") |>
    mutate(model = "ridge"),
  collect_metrics(lasso_res) |>
    filter(.metric == "rmse") |>
    inner_join(best_lasso, by = "penalty") |>
    mutate(model = "lasso")
) |>
  select(model, penalty, mean, std_err)
```

### Comment

Cross-validation selected a non-zero penalty for the LASSO model, indicating that it improves predictive performance. The LASSO regularization path shows a small set of predictors entering the model as the penalty decreases, highlighting its role as a variable selection method.

### Comment on selected predictors

The LASSO model selected a set of nine predictors. Remittance intensity is negatively associated with GDP per capita and macroeconomic instability, while unemployment, deportations, and internet access exhibit positive relationships, consistent with counter-cyclical and transaction-cost mechanisms.

### Why LASSO is useful

-   The dataset benefits from variable selection (LASSO), not from coefficient stabilization (RIDGE).

------------------------------------------------------------------------

## 10.5 Random Forest

We use this model a regularizaiton model, to reduce variance error by reducing the important of less important predictors. It is a bagging algorithm which considers each split and divides it into only useful predictors - It uses two hyper paramaters `mtry` which considers x predictors in each split (it can be tuned to optimal value of useful predictors. and `min_n` to stop spliting the data

```{r}
library(vip)
# For missingness inside the dependent variable 
remit_train_clean <- remit_train |>
  filter(!is.na(remittances_gdp))

# Smaller CV for run time optimization 
rf_folds <- vfold_cv(remit_train_clean, v = 5)

## Given the high degree of missingness a recipe that accounts for nas will avoid it from breaking down using median imputation. 
recipe_alt <- 
  recipe(remittances_gdp ~ stock + gdp_per + unemployment + dist_cap + terror + deportations + internet + inflation + country_name,
  data = remit_train_clean) |>
update_role(country_name, new_role = "id") |>
step_impute_median(all_numeric_predictors()) |>
step_lag(gdp_per, unemployment, lag = 1) |>
step_mutate(
    gdp_per = log(gdp_per + 1)) |>
step_normalize(all_numeric_predictors()) 

bake(prep(recipe_alt, training = remit_train_clean), new_data = remit_train_clean)

## Creating a Random Forest Model set up for tuning
rf_mod <- rand_forest(
  trees = tune(),
  mtry = tune(),
  min_n = tune()) |>
  set_mode(mode = "regression") |>
  set_engine(engine = "ranger", 
             importance = "impurity", 
             num.threads = 4)

## Creating a workflow. Need to use alternative specific because it accounts for missingness which will lead the model to fail. 
rf_wf <- workflow() |>
  add_recipe(recipe_alt) |>
  add_model(rf_mod)

## Finalize parameters

rf_params <- rf_wf |> 
  extract_parameter_set_dials() |>
  finalize(remit_train_clean)

rf_params


## tuning grid 
rf_grid <- grid_max_entropy(
  rf_params, 
  size = 20 )

## Tuning it within cross validation using our hyperparamters.
rf_tuned <- rf_wf |>
  tune_grid(
    resamples = rf_folds,
    grid = rf_grid,
    control = control_grid(save_pred = TRUE))

## Measuring the RMSE 
rf_tuned |>
  collect_metrics()

rf_tuned |> 
  show_best(metric = "rmse", n = 10)

## selecting the best specification and fit it to the full training data. 
best_rf <-rf_tuned |>
  select_best(metric = "rmse")

final_rf_wf <- rf_wf |> 
  finalize_workflow(best_rf)

final_rf_fit <- final_rf_wf |> 
  fit(data = remit_train_clean)

# Variable importance 
final_rf_fit |> 
  extract_fit_parsnip() |> 
  vip(num_features = 10)
```

------------------------------------------------------------------------

## 10.6 K-Nearest Neighbors (KNN)

KNN predicts remittances by averaging the values of the K most similar country-year observations.

```{r}
## Create lagged variables by country
remit_train_lagged <- remit_train |>
  arrange(country_name, year) |>
  group_by(country_name) |>
  mutate(
    gdp_lag = lag(gdp_per),
    deportations_lag = lag(deportations)
  ) |>
  ungroup()

## Remove missing values
remit_train_clean_knn <- remit_train_lagged |>
  select(remittances_gdp, stock, gdp_per, unemployment, dist_cap, 
         terror, deportations, internet, inflation, gdp_lag, deportations_lag) |>
  drop_na()

## Cross-validation setup
set.seed(20251211)
knn_folds <- vfold_cv(data = remit_train_clean_knn, v = 10, repeats = 5)

## Recipe: log transform and normalize
recipe_knn <- 
  recipe(remittances_gdp ~ ., data = remit_train_clean_knn) |>
  step_mutate(gdp_per = log(gdp_per + 1)) |>
  step_normalize(all_numeric_predictors())

## Model: KNN with tunable K
knn_mod <- 
  nearest_neighbor(neighbors = tune()) |>
  set_engine("kknn") |>
  set_mode("regression")

## Grid: test K from 1 to 99
knn_grid <- grid_regular(neighbors(range = c(1, 99)), levels = 10)

## Workflow
knn_workflow <- 
  workflow() |>
  add_recipe(recipe_knn) |>
  add_model(knn_mod)

## Tune
knn_results <- 
  knn_workflow |>
  tune_grid(
    resamples = knn_folds,
    grid = knn_grid,
    metrics = metric_set(rmse, rsq)
  )

## Results
knn_results |> collect_metrics()
knn_results |> show_best(metric = "rmse")
knn_results |> autoplot()

## Select best
best_k <- select_best(knn_results, metric = "rmse")
final_knn_wf <- knn_workflow |> finalize_workflow(best_k)
```

------------------------------------------------------------------------

## 10.7 Which Model is the best?

```{r}
## Compare all models
tibble(
  Model = c("OLS", "Ridge", "LASSO", "Random Forest", "KNN"),
  Error = c(
    collect_metrics(lm_results) |> filter(.metric == "rmse") |> pull(mean),
    collect_metrics(ridge_res) |> filter(.metric == "rmse") |> inner_join(best_ridge, by = "penalty") |> pull(mean),
    collect_metrics(lasso_res) |> filter(.metric == "rmse") |> inner_join(best_lasso, by = "penalty") |> pull(mean),
    collect_metrics(rf_tuned) |> filter(.metric == "rmse") |> slice_min(mean) |> pull(mean),
    collect_metrics(knn_results) |> filter(.metric == "rmse") |> slice_min(mean) |> pull(mean)
  )
) |>
  arrange(Error)
```

## Dot plot

```{r}
tibble(
  Model = c("OLS", "Ridge", "LASSO", "Random Forest", "KNN"),
  Error = c(
    collect_metrics(lm_results) |> filter(.metric == "rmse") |> pull(mean),
    collect_metrics(ridge_res) |> filter(.metric == "rmse") |> inner_join(best_ridge, by = "penalty") |> pull(mean),
    collect_metrics(lasso_res) |> filter(.metric == "rmse") |> inner_join(best_lasso, by = "penalty") |> pull(mean),
    collect_metrics(rf_tuned) |> filter(.metric == "rmse") |> slice_min(mean) |> pull(mean),
    collect_metrics(knn_results) |> filter(.metric == "rmse") |> slice_min(mean) |> pull(mean)
  )
) |>
  ggplot(aes(x = Error, y = reorder(Model, -Error))) +
  geom_point(size = 4, color = "steelblue") +
  geom_segment(aes(x = 0, xend = Error, y = Model, yend = Model), color = "gray70") +
  labs(title = "Model Performance", 
       subtitle = "Left is better",
       x = "Prediction Error", 
       y = NULL) +
  theme_minimal()
```

## 10.8 Test the Best Model on New Data

The best model is **Random Forest** (lowest error: 3.06). Now we test it on completely new data.

```{r}
## Create new split for Random Forest (uses clean data)
set.seed(20251211)
rf_split <- initial_split(remit_train_clean, prop = 0.8)

## Test Random Forest
test_results <- final_rf_wf |> last_fit(rf_split)

## Show results
test_results |> collect_metrics()
```

On average, predictions are off by 2.53 percentage points. The model explains 86% of the variation in remittances

```{r}
## Visualize: Actual vs Predicted
test_results |>
  collect_predictions() |>
  ggplot(aes(x = remittances_gdp, y = .pred)) +
  geom_point(alpha = 0.5, color = "steelblue") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "Random Forest: Test Set Performance",
    subtitle = "Points near line = good predictions",
    x = "Actual Remittances (% GDP)",
    y = "Predicted"
  ) +
  theme_minimal()
```

Random Forest performs **much better** than the other models!
